{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/mood2jam/artm-github/runs/4pl5av7m\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
       "            in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to connect to W&B servers after 10 seconds.                    Letting user process proceed while attempting to reconnect.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 9805824/9912422 [00:15<00:00, 772243.01it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28881 [00:05<?, ?it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1648877 [00:05<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 16384/1648877 [00:05<00:09, 163673.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 40960/1648877 [00:05<00:09, 168758.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 139264/1648877 [00:05<00:06, 219422.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 204800/1648877 [00:05<00:05, 262077.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 270336/1648877 [00:05<00:04, 299668.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 335872/1648877 [00:05<00:03, 345692.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 409600/1648877 [00:06<00:03, 381155.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 483328/1648877 [00:06<00:02, 419563.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 557056/1648877 [00:06<00:02, 458552.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 638976/1648877 [00:06<00:02, 478342.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 712704/1648877 [00:06<00:01, 507705.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 794624/1648877 [00:06<00:01, 533965.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 876544/1648877 [00:06<00:01, 557319.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 966656/1648877 [00:07<00:01, 580461.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 1056768/1648877 [00:07<00:00, 603720.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 1146880/1648877 [00:07<00:00, 621849.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 1245184/1648877 [00:07<00:00, 641832.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 1335296/1648877 [00:07<00:00, 666730.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 1433600/1648877 [00:07<00:00, 735835.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 1515520/1648877 [00:07<00:00, 699731.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 1597440/1648877 [00:07<00:00, 712623.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "1654784it [00:07, 207738.36it/s]                             \u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:30, 772243.01it/s]                             \n",
      "\n",
      "  0%|          | 0/4542 [00:05<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://app.wandb.ai/mood2jam/artm-github/runs/4pl5av7m?jupyter=true&state=running\" style=\"border:none;width:100%;height:420px\">\n",
       "        </iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.Run at 0x7f330c8b7710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.329947\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.305957\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.283383\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.261370\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.269774\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.224074\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.228971\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.147333\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.155427\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.090207\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.058486\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.936129\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.802123\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 1.703747\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.738562\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.604652\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.321524\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.384127\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.553027\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.040575\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.305330\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 1.203694\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 1.000380\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.957438\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 1.040422\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.166386\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.839103\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.891890\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.836892\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.900476\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.775762\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 1.029365\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 1.032767\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.585013\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.817835\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.706110\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.543097\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.853827\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.569050\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.887411\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.664255\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.868014\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.654796\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.691085\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.637053\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.682676\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.664519\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.711583\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.487535\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.819746\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.487743\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.471951\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.490639\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.430553\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.910600\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.535762\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.745159\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.473160\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.744494\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.770381\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.503195\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.521822\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.821591\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.516236\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.593126\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.465425\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.570889\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.335999\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.751689\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.741184\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.648358\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.481562\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.473138\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.534652\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.579165\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.518070\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.422152\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.567109\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.565517\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.259340\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.706095\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.305796\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.637035\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.413722\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.650210\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.382081\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.510765\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.334846\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.485084\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.488530\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.312646\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.512091\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.683633\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.501540\n",
      "\n",
      "Test set: Average loss: 0.2137, Accuracy: 9398/10000 (94%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://app.wandb.ai/mood2jam/artm-github/runs/4pl5av7m?jupyter=true&state=running\" style=\"border:none;width:100%;height:420px\">\n",
       "        </iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.Run at 0x7f3301162f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.448468\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.180039\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.297916\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.460931\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.327462\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.358046\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.297516\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.545024\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.217752\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.490155\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.536654\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.369331\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.376621\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.363079\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.523656\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.441914\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.570872\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.310292\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.352089\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.409302\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.479095\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.509152\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.689349\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.466652\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.390338\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.383143\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.588609\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.495708\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.312381\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.453958\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.295543\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.432384\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.497494\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.286130\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.510802\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.289575\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.418772\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.392304\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.315410\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.277135\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.288760\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.540986\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.628092\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.341546\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.237654\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.278199\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.349216\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.335078\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.363656\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.422752\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.658906\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.493529\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.320527\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.550663\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.362358\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.568962\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.274173\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.341141\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.276518\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.560514\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.313844\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.517495\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.414503\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.208153\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.353126\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.430903\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.487774\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.216753\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.208924\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.342361\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.523354\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.373235\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.508261\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.454823\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.416378\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.379455\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.221007\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.342376\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.277118\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.305463\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.468961\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.394683\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.427354\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.202444\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.497238\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.137703\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.283605\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.355408\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.201507\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.378514\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.294883\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.475333\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.363235\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.328643\n",
      "\n",
      "Test set: Average loss: 0.1241, Accuracy: 9624/10000 (96%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://app.wandb.ai/mood2jam/artm-github/runs/4pl5av7m?jupyter=true&state=running\" style=\"border:none;width:100%;height:420px\">\n",
       "        </iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.Run at 0x7f330c8b7588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.312023\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.349714\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.310286\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.223869\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.324996\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.305973\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.188197\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.307119\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.235760\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.274348\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.309410\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.279364\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.389765\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.275387\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.365855\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.180900\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.095339\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.248658\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.328801\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.316297\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.246815\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.306392\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.389575\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.328220\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.222027\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.323644\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.330842\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.498958\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.358058\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.371477\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.523433\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.267341\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.487857\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.383214\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.249724\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.317604\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.219542\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.354903\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.153746\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.202195\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.395211\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.141838\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.164797\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.277891\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.529602\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.523154\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.237284\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.200802\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.308507\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.356871\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.367255\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.220642\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.183100\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.702816\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.134483\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.200223\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.133848\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.341334\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.372016\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.327084\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.243914\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.224247\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.317610\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.276219\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.403008\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.183299\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.432542\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.184419\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.258056\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.345429\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.133262\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.325365\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.373393\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.388854\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.241064\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.187481\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.426534\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.292738\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.241956\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.565510\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.562129\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.170867\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.369348\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.286461\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.329620\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.163655\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.328224\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.371602\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.528043\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.264904\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.464337\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.326551\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.294738\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.629243\n",
      "\n",
      "Test set: Average loss: 0.0998, Accuracy: 9687/10000 (97%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://app.wandb.ai/mood2jam/artm-github/runs/4pl5av7m?jupyter=true&state=running\" style=\"border:none;width:100%;height:420px\">\n",
       "        </iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.Run at 0x7f32980d5f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.404313\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.258220\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.267172\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.302859\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.185593\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.265004\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.281264\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.268091\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.209720\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.385078\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.111203\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.358412\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.218182\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.356704\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.213415\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.256223\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.083748\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.258302\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.299979\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.242423\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.243886\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.157642\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.490042\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.375628\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.182464\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.269875\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.286935\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.156967\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.495571\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.327053\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.148898\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.427727\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.424689\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.384873\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.411573\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.208281\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.134450\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.096840\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.362733\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.237376\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.322775\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.405602\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.417554\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.268264\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.290305\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.155583\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.202126\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.453537\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.217901\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.329364\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.165759\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.431354\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.414682\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.224421\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.252037\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.287975\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.148468\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.145396\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.156212\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.371514\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.204590\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.180596\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.321294\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.299808\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.218544\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.301301\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.150616\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.463330\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.295799\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.365570\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.086398\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.136514\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.192897\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.207181\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.085961\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.096683\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.156892\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.476857\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.400781\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.260835\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.206854\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.254412\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.232073\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.248872\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.354218\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.180563\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.410952\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.231025\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.269295\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.135655\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.168583\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.450583\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.195325\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.290160\n",
      "\n",
      "Test set: Average loss: 0.0855, Accuracy: 9724/10000 (97%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://app.wandb.ai/mood2jam/artm-github/runs/4pl5av7m?jupyter=true&state=running\" style=\"border:none;width:100%;height:420px\">\n",
       "        </iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.Run at 0x7f32980db8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.260412\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.217509\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.194675\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.260973\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.139113\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.152747\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.268433\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.277689\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.222285\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.396048\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.214899\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.184893\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.454737\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.162552\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.139722\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.231433\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.475021\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.154074\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.217652\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.099251\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.277371\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.180330\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.244993\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.214206\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.246411\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.210939\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.307400\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.134753\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.163517\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.214214\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.456765\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.098774\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.215826\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.264604\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.140200\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.146486\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.249600\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.206727\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.199459\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.320713\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.279433\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.240223\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.241529\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.167047\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.442801\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.096488\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.259482\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.106725\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.193630\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.090136\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.312615\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.394371\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.526716\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.273407\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.222660\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.393767\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.117672\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.230604\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.209804\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.291763\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.141404\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.447531\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.098123\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.177001\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.200693\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.144015\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.073855\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.277955\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.120167\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.365968\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.139334\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.307775\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.367224\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.255856\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.175548\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.230373\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.273886\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.273198\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.278484\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.260021\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.239853\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.166756\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.344435\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.310825\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.117844\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.183760\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.278521\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.210938\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.114423\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.189490\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.286523\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.123643\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.534178\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.374855\n",
      "\n",
      "Test set: Average loss: 0.0731, Accuracy: 9764/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://app.wandb.ai/mood2jam/artm-github/runs/4pl5av7m?jupyter=true&state=running\" style=\"border:none;width:100%;height:420px\">\n",
       "        </iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.Run at 0x7f32980db2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.112221\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.164109\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.302137\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.292359\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.110126\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.323096\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.153170\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.265391\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.311157\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.057977\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.079859\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.311330\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.199783\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.343230\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.264876\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.266089\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.303109\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.125685\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.134333\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.136886\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.308954\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.109949\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.153946\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.214511\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.179330\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.168936\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.266624\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.071848\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.249541\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.152987\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.266634\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.225407\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.461992\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.236402\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.247844\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.296294\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.155160\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.334648\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.154233\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.139698\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.331062\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.287583\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.219913\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.112351\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.360612\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.113813\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.086051\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.199338\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.212323\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.152755\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.122626\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.210980\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.157201\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.193411\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.153457\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.130811\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.187644\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.385296\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.508194\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.233229\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.495507\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.217723\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.163621\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.163873\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.173669\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.069222\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.220008\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.159889\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.285784\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.168714\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.101223\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.205793\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.170675\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.174375\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.185372\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.173921\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.186976\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.135959\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.137532\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.500586\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.103115\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.072559\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.218023\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.183871\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.196954\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.093241\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.152374\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.068095\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.126223\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.193213\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.092011\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.083319\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.235651\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.333757\n",
      "\n",
      "Test set: Average loss: 0.0681, Accuracy: 9789/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://app.wandb.ai/mood2jam/artm-github/runs/4pl5av7m?jupyter=true&state=running\" style=\"border:none;width:100%;height:420px\">\n",
       "        </iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.Run at 0x7f3298090908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.184175\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.116059\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.096955\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.066129\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.090053\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.222706\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.246912\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.409161\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.147658\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.107919\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.206303\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.189799\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.237796\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.179685\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.235024\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.157822\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.160305\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.227663\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.566423\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.173337\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.110831\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.080419\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.284362\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.226842\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.418212\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.210899\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.318544\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.059790\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.249783\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.185823\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.311690\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.137558\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.255843\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.125878\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.227452\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.241419\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.085007\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.170326\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.164618\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.229298\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.130695\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.139492\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.056761\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.178401\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.115653\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.150847\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.223732\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.200576\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.067174\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.138894\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.199419\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.125322\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.112229\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.112205\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.103870\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.093603\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.116865\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.064697\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.243039\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.204336\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.110160\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.243600\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.268545\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.211726\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.092264\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.321979\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.278321\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.079839\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.062222\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.106003\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.201966\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.132780\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.126081\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.123958\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.309489\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.089396\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.276114\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.163361\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.094149\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.319192\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.365624\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.243235\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.109008\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.353265\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.122659\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.235697\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.113623\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.160467\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.055991\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.092898\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.262466\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.147418\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.247439\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.282677\n",
      "\n",
      "Test set: Average loss: 0.0651, Accuracy: 9809/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://app.wandb.ai/mood2jam/artm-github/runs/4pl5av7m?jupyter=true&state=running\" style=\"border:none;width:100%;height:420px\">\n",
       "        </iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.Run at 0x7f32980f0048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.182721\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.128183\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.156652\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.185457\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.143970\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.241879\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.129726\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.276812\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.102807\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.249292\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.581248\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.205736\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.197345\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.039092\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.164591\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.419758\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.200432\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.383817\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.195019\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.087626\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.160740\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.118610\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.120724\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.185822\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.240973\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.238320\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.177173\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.140522\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.097901\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.166181\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.213620\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.181635\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.261257\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.089116\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.141782\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.226149\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.124866\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.240263\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.081911\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.067604\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.240255\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.245704\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.290479\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.240042\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.212604\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.081535\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.278725\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.145148\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.130110\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.086398\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.209512\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.379317\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.072639\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.058833\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.264553\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.172709\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.137678\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.290132\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.315003\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.036588\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.137201\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.190142\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.133976\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.396185\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.402760\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.115786\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.077175\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.115275\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.166397\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.241874\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.093824\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.107733\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.092525\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.202599\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.203011\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.380826\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.037965\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.429141\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.190035\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.249796\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.290942\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.140114\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.174518\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.076659\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.090202\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.196225\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.142859\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.238456\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.135377\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.247844\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.115764\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.392629\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.098837\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.119189\n",
      "\n",
      "Test set: Average loss: 0.0572, Accuracy: 9829/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://app.wandb.ai/mood2jam/artm-github/runs/4pl5av7m?jupyter=true&state=running\" style=\"border:none;width:100%;height:420px\">\n",
       "        </iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.Run at 0x7f32980d5390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.152898\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.087329\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.197537\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.428648\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.158631\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.152940\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.119596\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.132819\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.121940\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.178738\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.089848\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.295716\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.092825\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.431144\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.162066\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.161917\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.258350\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.026501\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.189001\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.268461\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.167085\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.110476\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.216938\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.171987\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.409349\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.159026\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.140202\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.177235\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.245930\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.194703\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.504627\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.221372\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.255502\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.169012\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.194542\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.160955\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.174637\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.181190\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.127503\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.259585\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.144838\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.298663\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.144999\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.073818\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.354808\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.173615\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.047230\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.185690\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.101389\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.233900\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.141215\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.246072\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.309115\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.263133\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.187814\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.227906\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.043879\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.193603\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.096603\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.178838\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.082792\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.106598\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.083763\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.044833\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.143733\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.075316\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.048763\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.139566\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.107281\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.122080\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.103793\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.157117\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.126846\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.209504\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.232228\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.151962\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.074147\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.097896\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.116148\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.126282\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.025807\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.167727\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.055361\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.155779\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.216424\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.120817\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.161066\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.105799\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.114179\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.099695\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.169020\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.066411\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.051788\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.232974\n",
      "\n",
      "Test set: Average loss: 0.0546, Accuracy: 9830/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://app.wandb.ai/mood2jam/artm-github/runs/4pl5av7m?jupyter=true&state=running\" style=\"border:none;width:100%;height:420px\">\n",
       "        </iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.Run at 0x7f330c843748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.116314\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.098210\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.174129\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.206124\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.153446\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.177150\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.187996\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.149736\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.304400\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.068049\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.029727\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.078165\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.137668\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.157763\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.191453\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.280019\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.292457\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.226324\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.205355\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.206717\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.107882\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.073346\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.235568\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.070044\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.245844\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.173047\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.096735\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.382054\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.180270\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.118280\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.082476\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.159782\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.091971\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.137655\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.206550\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.085880\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.043551\n",
      "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.172094\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.227174\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.176842\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.241169\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.269618\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.217124\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.148944\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.108057\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.112631\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.215695\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.113026\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.078528\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.310041\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.196729\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.181002\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.051673\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.136255\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.109913\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.136249\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.125841\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.277652\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.160875\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.106848\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.155343\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.373152\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.301174\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.110947\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.178828\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.112291\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.080978\n",
      "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.106944\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.129398\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.151403\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.086222\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.168545\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.227096\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.129376\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.082468\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.152483\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.376865\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.224488\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.092808\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.134485\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.147356\n",
      "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.032084\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.085042\n",
      "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.061897\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.210937\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.100327\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.244053\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.178778\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.504041\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.105280\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.265910\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.136460\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.183042\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.227979\n",
      "\n",
      "Test set: Average loss: 0.0519, Accuracy: 9854/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import wandb\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    example_images = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            # Save the first inbput tensor in each test batch as an example image\n",
    "            example_images.append(wandb.Image(data[0], caption=\"Pred: {} Truth: {}\".format(pred[0].item(), target[0])))\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "    # Log the images and metrics\n",
    "    wandb.log({\n",
    "            \"Examples\": example_images,\n",
    "            \"Test Accuracy\": 100. * correct / len(test_loader.dataset),\n",
    "            \"Test Loss\": test_loss})\n",
    "\n",
    "def main():\n",
    "    wandb.init()\n",
    "\n",
    "    # Training settings\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                        help='input batch size for testing (default: 1000)')\n",
    "    parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                        help='number of epochs to train (default: 10)')\n",
    "    parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                        help='learning rate (default: 0.01)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                        help='SGD momentum (default: 0.5)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "#     args = parser.parse_args()\n",
    "#     args = parser.parse_args(argv[1:])\n",
    "    args = parser.parse_known_args()[0]\n",
    "    \n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    # We load all of the arguments into config to save as hyperparameters\n",
    "    wandb.config.update(args)\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "    # This magic line lets us save the pytorch model and track all of the gradients and optionally parameters\n",
    "    wandb.watch(model)\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        %wandb\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(args, model, device, test_loader)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ab6c1d3957d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-ab6c1d3957d9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m     parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n\u001b[1;32m     91\u001b[0m                         help='how many batches to wait before logging training status')\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_cuda\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unrecognized arguments: %s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1752\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1753\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2499\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2500\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2501\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2486\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2487\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2488\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2490\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "%tb\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
